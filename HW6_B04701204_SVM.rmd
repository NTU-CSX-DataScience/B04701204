---
title: "HW6_B04701204_SVM"
author: "B04701204"
date: "2017年12月7日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##題目：有效分類不同的酒種 - SVM 演算法

### 資料輸入 - Wine Dataset

從 LIBSVM Data 取得 wine dataset (<https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/wine.scale>)。
透過`read.libsvm.R` 讀入資料並整理之。

```{r source}
#read in the data and convert to dataframe
source( 'read.libsvm.R' )
```

```{r read}
wine = read.libsvm( 'wine.scale', 13 )
wine = as.data.frame(wine)

#reassign attributes
names(wine) = c("type","alc","acid","ash","alk","mag","phenols","flav","nonflav","proanth","color","hue","OD","proline")

#encode wine type as factor
wine$type = as.factor(wine$type)
```

### 套件執行
```{r library}
library(e1071)
library(dplyr)
library(lattice)
library(ggplot2)
library(caret)
```

### 繪圖

透過繪圖找出能最能明顯區分出不同酒種的兩個變量。

#### Scatter Plot - Wine Dataset

先繪製所有變量的 scatter plot，找出較能明顯區分出不同酒種的變量組合。

```{r plot}
#plot wine dataset
plot(wine)
```

#### Scatter Plot - Specific Variable Sets

取出上述繪圖中，較能明顯區分出不同酒種的變量組合再做 `plot`，找出最能明顯區分出不同酒種的變量組合。

```{r plot2}
#plot(wine$acid, wine$OD, col=wine$type)
#plot(wine$acid, wine$phenols, col=wine$type)
#plot(wine$OD, wine$phenols, col=wine$type)
#plot(wine$color, wine$hue, col=wine$type)
#plot(wine$alc, wine$color, col=wine$type)
#plot(wine$alc, wine$hue, col=wine$type) 
#plot(wine$alc, wine$flav, col=wine$type) 
#plot(wine$flav, wine$color, col=wine$type)

plot(wine$flav, wine$hue, col=wine$type)
```

在以上各變量組合的 trial & error 後，發現組合 (flav, hue) 最能明顯區分出不同酒種。

### SVM 演算法

首先先建立新的dataset，其中包含因變量類黃酮含量 (flav)、色澤(hue) ，以及自變量酒種 (type)。

```{r dta}
#create new, smaller dataset
col = c("flav","hue","type")
dta = wine %>%
  select(col)
```

其次，建立 testing data。

```{r testing}
#create testing samples
testId = sample(nrow(dta),78, replace=FALSE)

x <- subset(dta[testId,], select = -type)
y <- dta$type[testId]
```

最後，透過 SVM 演算法得出 training model，代入 testing data 以測試成效。透過繪製 `confusionMatrix(pred,y)` ，得到預測模型準確率高達96%。

```{r svm}
#training model
trainingId = dta[-testId,]
svm_model1 = 
  svmfit = svm(type ~ ., data = dta[-testId,])

pred = predict(svm_model1,x)
confusionMatrix(pred,y)
```

